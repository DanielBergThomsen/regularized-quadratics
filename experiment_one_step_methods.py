from typing import Union, List
import pandas as pd
from matplotlib import rc
import matplotlib.pyplot as plt
import numpy as np

import fire

from experiment.runner import run_experiment


def generate_plots(dataframe: pd.DataFrame, path: str):
    """Generates figures of norm distances to solution based on dataframe generated by runner.py.

    Args:
        dataframe (pd.DataFrame): Dataframe containing norm distance data resulting from runner.py.
        path (str, optional): Full save path.
    """

    rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})
    rc('text', usetex=True)
    fsize = 15
    fsize_theory = 25
    line_thickness = 3
    line_offset = 0.75
    
    groupby_keys = ['min_eig', 'max_eig', 'regularization_strength', 'power', 'dimension', 'solution_norm', 'eigendist', 'pidist']
    for key, group in dataframe.groupby(groupby_keys, dropna=False):

        # Unpack key
        (mu, L, s, p, d, r, eigendist, pidist) = key

        # Setup axis with log-log scale
        fig, ax = plt.subplots()
        ax.set_xscale('symlog')
        ax.set_yscale('log')
        ax.minorticks_off()
            
        # Plot per-iteration norm distance to the solution for the gradient method
        fres_gd = group[group['method'] == 'GD'].groupby('iteration')['norm_dist'].min()
        wcx = np.array(fres_gd.index)
        wcy = np.array(fres_gd)
        label_gd = 'Gradient method'
        ax.plot(wcx, wcy, color='red', label=label_gd, linewidth=line_thickness+3)

        # Plot per-iteration norm distance to the solution for the composite gradient method
        fres_cgm = group[group['method'] == 'CGM'].groupby('iteration')['norm_dist'].min()
        wcx = np.array(fres_cgm.index)
        wcy = np.array(fres_cgm)
        label_cgm = 'Composite gradient method'
        ax.plot(wcx, wcy, color='green', label=label_cgm, linewidth=line_thickness, linestyle='-.')

        # If power is an integer, set it to the string of that integer
        power = p - 2
        if power.is_integer():
            power_str = str(int(power))
            if power_str == '1':
                power_str = ''
        else:
            power_str = r'p-2'

        # Plot theoretical lower bound
        lower_bound = r * np.array([(1 - (mu + s*r**(p-2))/(L + s*r**(p-2)))**i for i in range(len(wcx))])
        ax.plot(wcx, lower_bound, color='blue', 
                linewidth=line_thickness,
                linestyle='--')

        iterations = np.arange(1, wcx.max()+1)
        visual_middle = int(np.sqrt(iterations[0] * iterations[-1]))
        dx = np.diff(iterations)[visual_middle]
        unif_dy = np.diff(lower_bound)[visual_middle]
        unif_angle = np.rad2deg(np.arctan2(unif_dy, dx)) * 1.4
        ax.text(iterations[visual_middle], 
                lower_bound[visual_middle], 
                '\n' + r'$r \cdot \Bigg(1 - \frac{\mu + sr^{' + power_str + r'}}{L + sr^{' + power_str + r'}}\Bigg)^k$', 
                linespacing = line_offset,
                transform_rotates_text=True,
                rotation=unif_angle,
                rotation_mode='anchor',
                color='blue', 
                fontweight='bold', 
                fontsize=fsize_theory,
                horizontalalignment='center', 
                verticalalignment='top')

        # Hide bounding box
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        ax.spines['left'].set_visible(False)

        ax.legend(loc='lower left', fontsize=fsize)

        ax.set_xlabel(r'Number of iterations $k$', fontsize=fsize)
        ax.set_ylabel(r'$\|x_k - x_\star\|$', fontsize=fsize)

        plt.grid()

        fig.savefig(path)
        plt.close(fig)


def main(repetitions: int = 1,
         min_eig: Union[float, List[float]] = 0,
         max_eig: Union[float, List[float]] = 100,
         regularization: Union[float, List[float]] = 1,
         power: Union[int, List[int]] = 3,
         dimensions: int = 100,
         solution_dist: Union[float, str, List[float]] = 1,
         problem_type: str = 'one_step_construction',
         solvers: Union[str, List[str]] = ['GD', 'CGM']):
    """Main function for running experiments and generating plots.

    Default arguments correspond to Figure 2 in the paper.
    
    Args:
        repetitions (int, optional): Number of times to repeat experiment. Defaults to 1.
        min_eig (Union[float, List[float]], optional): Smallest eigenvalue of A. Defaults to 0.
        max_eig (Union[float, List[float]], optional): Largest eigenvalue of A. Defaults to 1000.
        regularization (Union[float, List[float]], optional): Regularization strength (s). Defaults to 1.
        power (Union[int, List[int]], optional): Power of the regularizer. Defaults to 3.
        dimensions (int, optional): Dimension of problem instance. Defaults to 100.
        solution_dist (Union[float, str, List[float]], optional): Norm of the solution vector. Defaults to 'worst_case'.
        problem_type (str, optional): Problem type (cf. problem_generator_factory in regularized_quadratic.py).
        Defaults to 'one_step_construction'.
        solvers (Union[str, List[str]], optional): Solvers to use (cf. run_experiment from runner.py). Defaults to ['krylov_method, GD'].
    """

    N = dimensions * 10
    df = run_experiment(
        repetitions = repetitions, 
        min_eig = min_eig, 
        max_eig = max_eig, 
        regularization = regularization, 
        power = power, 
        dimensions = dimensions, 
        solution_dist = solution_dist, 
        iterations = N,
        problem_type = problem_type, 
        solvers = solvers,
    )

    # Save plots
    generate_plots(df, 'figures/one_step_construction.pdf')


if __name__ == '__main__':
    fire.Fire(main)
